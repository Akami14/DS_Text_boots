{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Тема «POS-tagger и NER»\n",
        "Задание\n",
        " 1. Написать теггер на данных с русским языком\n",
        "проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
        "написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
        "сравнить все реализованные методы, сделать выводы  \n",
        "\n",
        "\n",
        "Задание 2. Проверить, насколько хорошо работает NER\n",
        "Данные брать из Index of /pub/named_entities\n",
        "проверить NER из nltk/spacy/deeppavlov.\n",
        "написать свой NER, попробовать разные подходы.\n",
        "передаём в сетку токен и его соседей.\n",
        "передаём в сетку только токен.\n",
        "свой вариант.\n",
        "сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score.\n"
      ],
      "metadata": {
        "id": "SCV8Q1gk_Lay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 UnigramTagger, BigramTagger, TrigramTagger"
      ],
      "metadata": {
        "id": "0glEywIf_1Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pyconll -q\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import brown\n",
        "\n",
        "import pyconll\n",
        "import nltk\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger"
      ],
      "metadata": {
        "id": "fuRZs0lq_NhI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "!wget -q -O ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget -q -O ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "metadata": {
        "id": "FFeaYs0IFtdX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = pyconll.load_from_file('ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
      ],
      "metadata": {
        "id": "ce91koiSGA5J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[el.text for el in full_train][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fpc097SOEsQ",
        "outputId": "71ccce57-c5db-4c48-8ee4-2153902ed456"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Анкета.',\n",
              " 'Начальник областного управления связи Семен Еремеевич был человек простой, приходил на работу всегда вовремя, здоровался с секретаршей за руку и иногда даже писал в стенгазету заметки под псевдонимом \"Муха\".',\n",
              " 'В приемной его с утра ожидали посетители, - кое-кто с важными делами, а кое-кто и с такими, которые легко можно было решить в нижестоящих инстанциях, не затрудняя Семена Еремеевича.',\n",
              " 'Однако стиль работы Семена Еремеевича заключался в том, чтобы принимать всех желающих и лично вникать в дело.',\n",
              " 'Приемная была обставлена просто, но по-деловому.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in full_train[1:2]:\n",
        "    for token in sent[:3]:\n",
        "        print(token.form, token.upos)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i86UJNP2GA7t",
        "outputId": "70ea51dd-c297-48c7-c35c-b7d1468c92cc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начальник NOUN\n",
            "областного ADJ\n",
            "управления NOUN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
        "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
        "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
        "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgLWFkW8Nir9",
        "outputId": "c7b97d7a-90a9-4e8b-9204-cf3cbf78645b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наибольшая длина предложения 194\n",
            "Наибольшая длина токена 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Заполним данными\n",
        "data_train = []\n",
        "for sent in full_train[:]:\n",
        "    data_train.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "data_test = []\n",
        "for sent in full_test[:]:\n",
        "    data_test.append([(token.form, token.upos) for token in sent]) # form - само слово  upos - форма\n",
        "\n",
        "data_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    data_sent_test.append([token.form for token in sent])"
      ],
      "metadata": {
        "id": "CQoQ_ueBNtgl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for el in data_train[1:2]:\n",
        "  print(el[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki_d4gxbUoxx",
        "outputId": "74cc99cb-c184-4ac6-8f4a-4b48d488e782"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('связи', 'NOUN')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(data_train)\n",
        "unigram_acc = unigram_tagger.accuracy(data_test)\n",
        "\n",
        "bigram_tagger = BigramTagger(data_train)\n",
        "bigram_acc = bigram_tagger.accuracy(data_test)\n",
        "\n",
        "trigram_tagger = TrigramTagger(data_train)\n",
        "trigram_acc = trigram_tagger.accuracy(data_test)\n",
        "\n",
        "# Комбинации\n",
        "# 2+1\n",
        "bigram_tagger = BigramTagger(data_train, backoff=unigram_tagger) # backoff=unigram_tagger - + unigram к bigram модели\n",
        "bigram_unigram_acc = bigram_tagger.accuracy(data_test)\n",
        "# 3+2+1\n",
        "trigram_tagger = TrigramTagger(data_train, backoff=bigram_tagger)\n",
        "trigram_bigram_unigram_acc = trigram_tagger.accuracy(data_test)\n",
        "\n",
        "# 3+1\n",
        "unigram_tagger_1 = UnigramTagger(data_train)\n",
        "trigram_tagger_2 = TrigramTagger(data_train, backoff=unigram_tagger)\n",
        "trigram_unigram_acc = trigram_tagger_2.accuracy(data_test)\n",
        "\n",
        "print(f'Accuracy:\\nUnigram Tagger: {round(unigram_acc, 5)},\\nBigram Tagger: {round(bigram_acc, 5)},\\n'\n",
        "      f'Trigram Tagger: {round(trigram_acc, 5)},\\nBigram and Unigram Tagger: {round(bigram_unigram_acc, 5)},\\n'\n",
        "      f'Trigram, Bigram and Unigram Tagger: {round(trigram_bigram_unigram_acc, 5)},\\n'\n",
        "      f'Trigram and Unigram Tagger: {round(trigram_unigram_acc, 5)},')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6PLMBhuUpDR",
        "outputId": "44e1fe17-7ca3-4b2b-969b-9a342b7d8b04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:\n",
            "Unigram Tagger: 0.82373,\n",
            "Bigram Tagger: 0.60939,\n",
            "Trigram Tagger: 0.17786,\n",
            "Bigram and Unigram Tagger: 0.82928,\n",
            "Trigram, Bigram and Unigram Tagger: 0.82914,\n",
            "Trigram and Unigram Tagger: 0.82855,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN')\n",
        "tag = backoff_tagger(data_train,\n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],\n",
        "                     backoff = backoff)\n",
        "print('UnigramTagger, BigramTagger, TrigramTagger')\n",
        "tag.accuracy(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_YFupFNkXGa",
        "outputId": "1db72ed5-8653-425e-f6af-e127f0656a47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnigramTagger, BigramTagger, TrigramTagger\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.827905462595221"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag = backoff_tagger(data_train,\n",
        "                     [UnigramTagger, BigramTagger],\n",
        "                     backoff = backoff)\n",
        "print('UnigramTagger, BigramTagger')\n",
        "tag.accuracy(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_kG-lAlVfO",
        "outputId": "d610bab7-6c7a-4a19-90f8-0916ab067154"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnigramTagger, BigramTagger\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8275343446838986"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tag = backoff_tagger(data_train,\n",
        "                     [UnigramTagger, TrigramTagger],\n",
        "                     backoff = backoff)\n",
        "print('UnigramTagger, TrigramTagger')\n",
        "tag.accuracy(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCxoqyr1lesP",
        "outputId": "e46626c1-9508-4c6e-bc6d-f1056c21e9c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnigramTagger, TrigramTagger\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8273650628296113"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tag = backoff_tagger(data_train,\n",
        "                     [ BigramTagger, TrigramTagger],\n",
        "                     backoff = backoff)\n",
        "print('BigramTagger, TrigramTagger')\n",
        "tag.accuracy(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-AUDk17lp9P",
        "outputId": "52234885-ad65-479c-cd48-4bdffc2053e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigramTagger, TrigramTagger\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1750309264926102"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "Из одиночных тегеов лучший результат показывает юниграм, Комбинации юниграма биграма и тригама как в парах так и втройках показывают схожие резудьтаты. Лучшим вариантом по точности -   Bigram and Unigram Tagger. Однако использование только Unigram Tagger будет быстрее метрика не сильно отличается. Комбинация  BigramTagger, TrigramTagger показывает неудовлетворительный результат"
      ],
      "metadata": {
        "id": "h_8ftzxZg3v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "-ailsj2MUpIX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Переведём тренировочный датасет в списки слов и списки POS-разметки\n",
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in data_train[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append(tok[0])\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "\n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in data_test[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append(tok[0])\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ],
      "metadata": {
        "id": "NmnliMBodRdD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tok[:4], train_label[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pW6Yi2BG0Ld",
        "outputId": "6b9b4544-855c-4dcd-9f0d-1ea9110f0eff"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Анкета', '.', 'Начальник', 'областного'], ['NOUN', 'PUNCT', 'NOUN', 'ADJ'])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_tok = ['' if item is None else item for item in test_tok]\n",
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)\n",
        "\n",
        "test_enc_labels = le.transform(test_label)\n",
        "\n",
        "\n",
        "\n",
        "for vectorizer in [CountVectorizer, HashingVectorizer, TfidfVectorizer]:\n",
        "\n",
        "    scaler = StandardScaler(with_mean=False)\n",
        "    coder = vectorizer(ngram_range=(1, 5), analyzer='char')\n",
        "\n",
        "\n",
        "    X_train = coder.fit_transform(train_tok)\n",
        "    X_test = coder.transform(test_tok)\n",
        "\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "    lr = LogisticRegression(random_state=0, max_iter = 100, n_jobs=7)\n",
        "    lr.fit(X_train, train_enc_labels)\n",
        "\n",
        "    pred = lr.predict(X_test)\n",
        "\n",
        "    print(vectorizer, accuracy_score(test_enc_labels, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I-w4gBsGr05",
        "outputId": "676196b4-dfa7-45aa-c50f-337b01d5cf3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.feature_extraction.text.CountVectorizer'> 0.9295527052542483\n",
            "<class 'sklearn.feature_extraction.text.HashingVectorizer'> 0.934859040302103\n",
            "<class 'sklearn.feature_extraction.text.TfidfVectorizer'> 0.9362588710202487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus -q"
      ],
      "metadata": {
        "id": "bA1Q91ltHH70"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M65efeDasZb",
        "outputId": "70b1d4ee-da2a-4f64-f5ae-f5b841394dfd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel -q"
      ],
      "metadata": {
        "id": "YsI_OMcXh1Bn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import corus\n",
        "from corus import load_ne5\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input, Bidirectional,Reshape\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "from razdel import tokenize\n",
        "\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdG0hItfHMLv",
        "outputId": "1d768163-fa5a-498d-a477-6fec3bdb91e3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "_0b493UkuSk5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ],
      "metadata": {
        "id": "lOt71CaWHOvx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q collection5.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnl1qq46a1Bq",
        "outputId": "9ce01f93-8551-40ae-f32f-f5a76c219c12"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Collection5/001.ann? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выявление NER с пмощью nltk"
      ],
      "metadata": {
        "id": "ilKJKnk5oxoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью функции nltk.ne_chunk ( на уже обученном наборе с помощью nltk.pos_tag - определяет части речи) можно распознавать именованные сущности с помощью классификатора, который добавляет метки категорий, такие как PERSON, ORGANIZATION и GPE."
      ],
      "metadata": {
        "id": "7deR2_iFoFA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = load_ne5('Collection5/')\n",
        "document = next(records).text\n",
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0iJK19qHaWjX",
        "outputId": "b2f8e1d2-4ccc-458c-8db0-72e55ec80981"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Д.Медведев сменил полпреда в СЗФО.\\r\\n\\r\\nПрезидент РФ Дмитрий Медведев освободил Илью Клебанова с поста полномочного представителя президента в Северо-Западном федеральном округе (СЗФО) в связи с переходом на другую работу. Об этом сообщает пресс-служба Кремля. Полпредом в СЗФО назначен Николай Винниченко.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAxadfgGHW5C",
        "outputId": "98627c1b-7e28-426d-d7ea-ccaec10bc832"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Николай Винниченко', 'PERSON'),\n",
              " ('РФ Дмитрий Медведев', 'ORGANIZATION'),\n",
              " ('СЗФО', 'ORGANIZATION')}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document = next(records).text\n",
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlEc-OithgZi",
        "outputId": "eb433077-ad82-46f5-9679-61aa0e9024e5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Александр', 'PERSON'),\n",
              " ('БКК', 'ORGANIZATION'),\n",
              " ('Банк', 'PERSON'),\n",
              " ('Более', 'PERSON'),\n",
              " ('Валерия Вакульчика', 'PERSON'),\n",
              " ('Валерия Иванова', 'PERSON'),\n",
              " ('Виктора Лукашенко', 'PERSON'),\n",
              " ('Вы', 'PERSON'),\n",
              " ('Иванов', 'PERSON'),\n",
              " ('Иванова мы', 'PERSON'),\n",
              " ('Кроме', 'PERSON'),\n",
              " ('Лукашенко', 'GPE'),\n",
              " ('Лукашенко', 'PERSON'),\n",
              " ('Минске', 'PERSON'),\n",
              " ('Надо', 'PERSON'),\n",
              " ('Отметим', 'PERSON'),\n",
              " ('Поэтому', 'PERSON'),\n",
              " ('России', 'PERSON'),\n",
              " ('Сергей Румас', 'PERSON'),\n",
              " ('Совмина Белоруссии', 'PERSON')}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы\n",
        "#### nltk.ne_chunk имет не плохой TPR показатель однако тащит за собой много FPR обьектов"
      ],
      "metadata": {
        "id": "p_mA06aaZ8y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выявление  NER c помощью Нейросетей"
      ],
      "metadata": {
        "id": "ygtd7koRXNof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        # if \"http://\" in input:\n",
        "        #   token='None'\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)\n",
        "\n",
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ],
      "metadata": {
        "id": "BZh6NdYUaD7V"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VVgd00_mpwyv",
        "outputId": "29868560-1a7c-49e1-d34d-d8819de496e8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             word  tag\n",
              "0               В  OUT\n",
              "1  Европарламенте  ORG\n",
              "2          избран  OUT\n",
              "3           новый  OUT\n",
              "4    председатель  OUT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-378b9f9c-abf3-4d91-968d-54e0ca4b78e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>В</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Европарламенте</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>избран</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>новый</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>председатель</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-378b9f9c-abf3-4d91-968d-54e0ca4b78e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-378b9f9c-abf3-4d91-968d-54e0ca4b78e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-378b9f9c-abf3-4d91-968d-54e0ca4b78e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd2f4748-1179-4aa3-a888-8de3a30cb8f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd2f4748-1179-4aa3-a888-8de3a30cb8f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd2f4748-1179-4aa3-a888-8de3a30cb8f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_words"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)\n"
      ],
      "metadata": {
        "id": "FTqNxuhVULEl"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.apply(len).max(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptVf7HM6qlmZ",
        "outputId": "f0f7b78b-1d60-4895-b1a3-b9fbb1c367cb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_data = train_data.batch(3056)\n",
        "valid_data = valid_data.batch(3056)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 30"
      ],
      "metadata": {
        "id": "Q8wdekNFUVqV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сеть прямого распространения"
      ],
      "metadata": {
        "id": "QZfCbxsSrhtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_len\n",
        "    )\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)\n",
        "t=np.unique(encoder.inverse_transform(y_test),return_counts=True)[1]\n",
        "t=t/t.sum()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(82, activation='relu'),\n",
        "  Dropout(0.6),\n",
        "  Dense(6, activation='relu'),\n",
        "  ])\n",
        "\n",
        "optim = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
        "model.compile(optimizer = optim,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics = ['accuracy'])\n",
        "              #metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
        "model.fit(train_data, validation_data=valid_data, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46yK53-krMss",
        "outputId": "4d9ace6c-8b30-4357-c952-d5cdc3357cac"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "65/65 [==============================] - 5s 66ms/step - loss: 0.9427 - accuracy: 0.8309 - val_loss: 0.6046 - val_accuracy: 0.8331\n",
            "Epoch 2/10\n",
            "65/65 [==============================] - 3s 47ms/step - loss: 0.9361 - accuracy: 0.6180 - val_loss: 1.3358 - val_accuracy: 0.3044\n",
            "Epoch 3/10\n",
            "65/65 [==============================] - 3s 48ms/step - loss: 1.0986 - accuracy: 0.4631 - val_loss: 0.9577 - val_accuracy: 0.5184\n",
            "Epoch 4/10\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 0.7833 - accuracy: 0.6331 - val_loss: 0.6655 - val_accuracy: 0.6865\n",
            "Epoch 5/10\n",
            "65/65 [==============================] - 4s 59ms/step - loss: 0.6693 - accuracy: 0.6873 - val_loss: 0.6492 - val_accuracy: 0.6946\n",
            "Epoch 6/10\n",
            "65/65 [==============================] - 3s 53ms/step - loss: 0.6088 - accuracy: 0.7169 - val_loss: 0.6842 - val_accuracy: 0.6716\n",
            "Epoch 7/10\n",
            "65/65 [==============================] - 4s 56ms/step - loss: 0.6392 - accuracy: 0.6889 - val_loss: 0.6937 - val_accuracy: 0.6655\n",
            "Epoch 8/10\n",
            "65/65 [==============================] - 3s 48ms/step - loss: 0.6165 - accuracy: 0.7045 - val_loss: 0.6805 - val_accuracy: 0.6733\n",
            "Epoch 9/10\n",
            "65/65 [==============================] - 3s 47ms/step - loss: 0.6191 - accuracy: 0.6987 - val_loss: 0.6806 - val_accuracy: 0.6720\n",
            "Epoch 10/10\n",
            "65/65 [==============================] - 3s 48ms/step - loss: 0.6206 - accuracy: 0.7296 - val_loss: 0.6713 - val_accuracy: 0.7706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a09df3ea410>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predicted_categories = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "9_vGWWQf2HkY"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " predicted_categories, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4a37_ZJ2Izb",
        "outputId": "5ac59ad4-3e87-4752-c994-f79c5e0d918f"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4, 4, 4, ..., 4, 4, 4]), array([4, 5, 4, ..., 4, 4, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predicted_categories), len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPof1Rh720UY",
        "outputId": "fce37263-2520-472e-d31d-74e73e9e66de"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65903, 65903)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clr = classification_report(y_test, predicted_categories)\n",
        "print( clr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb07C7LF2fta",
        "outputId": "1bf3bafe-c528-4309-efa6-549b9abf5903"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.95      0.15      1096\n",
            "           1       0.85      0.04      0.07      1098\n",
            "           2       0.00      0.00      0.00       592\n",
            "           3       0.92      0.04      0.08      3383\n",
            "           4       0.94      0.90      0.92     54451\n",
            "           5       0.98      0.13      0.22      5283\n",
            "\n",
            "    accuracy                           0.77     65903\n",
            "   macro avg       0.63      0.34      0.24     65903\n",
            "weighted avg       0.92      0.77      0.79     65903\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Рекурентная сеть"
      ],
      "metadata": {
        "id": "WgCF9k5froQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    vectorize_layer,\n",
        "    Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\n",
        "    Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.6),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_data, validation_data=valid_data, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1_yIb4KUeWt",
        "outputId": "d951a343-e7fa-4bb0-8c96-6295d62c4d4c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "65/65 [==============================] - 161s 2s/step - loss: 1.1105 - accuracy: 0.8113 - val_loss: 0.4965 - val_accuracy: 0.8282\n",
            "Epoch 2/10\n",
            "65/65 [==============================] - 116s 2s/step - loss: 0.4303 - accuracy: 0.8493 - val_loss: 0.3877 - val_accuracy: 0.8866\n",
            "Epoch 3/10\n",
            "65/65 [==============================] - 115s 2s/step - loss: 0.3139 - accuracy: 0.9006 - val_loss: 0.2988 - val_accuracy: 0.9051\n",
            "Epoch 4/10\n",
            "65/65 [==============================] - 115s 2s/step - loss: 0.2349 - accuracy: 0.9256 - val_loss: 0.2569 - val_accuracy: 0.9251\n",
            "Epoch 5/10\n",
            "65/65 [==============================] - 117s 2s/step - loss: 0.1909 - accuracy: 0.9413 - val_loss: 0.2395 - val_accuracy: 0.9304\n",
            "Epoch 6/10\n",
            "65/65 [==============================] - 116s 2s/step - loss: 0.1682 - accuracy: 0.9495 - val_loss: 0.2308 - val_accuracy: 0.9380\n",
            "Epoch 7/10\n",
            "65/65 [==============================] - 117s 2s/step - loss: 0.1532 - accuracy: 0.9560 - val_loss: 0.2246 - val_accuracy: 0.9401\n",
            "Epoch 8/10\n",
            "65/65 [==============================] - 115s 2s/step - loss: 0.1428 - accuracy: 0.9586 - val_loss: 0.2226 - val_accuracy: 0.9405\n",
            "Epoch 9/10\n",
            "65/65 [==============================] - 116s 2s/step - loss: 0.1361 - accuracy: 0.9604 - val_loss: 0.2220 - val_accuracy: 0.9412\n",
            "Epoch 10/10\n",
            "65/65 [==============================] - 116s 2s/step - loss: 0.1308 - accuracy: 0.9612 - val_loss: 0.2230 - val_accuracy: 0.9410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a0a5740ee90>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predicted_categories = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "NhplZJQN4Hls"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clr = classification_report(y_test, predicted_categories)\n",
        "print( clr);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdGX06_u4Q7B",
        "outputId": "85006ed2-9abd-44ce-f251-166a9dc08451"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90      1096\n",
            "           1       0.85      0.77      0.81      1098\n",
            "           2       0.91      0.77      0.83       592\n",
            "           3       0.91      0.54      0.67      3383\n",
            "           4       0.94      1.00      0.97     54451\n",
            "           5       0.99      0.70      0.82      5283\n",
            "\n",
            "    accuracy                           0.94     65903\n",
            "   macro avg       0.92      0.78      0.83     65903\n",
            "weighted avg       0.94      0.94      0.94     65903\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы\n",
        "### рекурентная сеть лучше справляется с задачей NER. В целом сеть можно еще дообучить. Переобучения что в сети прямого распостранения что в рекурентной не наблюдается. Сеть прямого распостранения плохо класифицирует 2 класс"
      ],
      "metadata": {
        "id": "xjCCvOPX-lMm"
      }
    }
  ]
}